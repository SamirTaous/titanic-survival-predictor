# Importing Libraries

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns


# 1 - Data Visualization

df = pd.read_csv("train.csv")
df.head(10)


df.info()
df.describe()


df['Survived'].value_counts(normalize=True)


sns.countplot(x="Survived", data=df)


sns.countplot(x="Pclass", hue="Survived", data=df)


sns.countplot(x='Embarked', hue='Survived', data=df)


sns.histplot(data=df, x="Age", bins=20, hue="Survived", kde=True)


# 2 - Data Cleaning

df.isnull().sum()


# Fill missing Age values with the median
df['Age'].fillna(df['Age'].median(), inplace=True)

# Fill missing Embarked values with the mode (most common port)
df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)

# Drop Cabin — too many missing values
df.drop('Cabin', axis=1, inplace=True)

# Drop irrelevant columns that won’t help model prediction
df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)


# Change categorical data to numbers

df= pd.get_dummies(df, columns=['Embarked', 'Sex'], drop_first=True)


# 3 - Train & Evaluate a Classifier

X = df.drop('Survived', axis=1)
y = df['Survived']


from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


from sklearn.ensemble import RandomForestClassifier

fmodel = RandomForestClassifier(random_state=42)
fmodel.fit(X_train, y_train)


y_pred = fmodel.predict(X_test)


from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

print('Accuracy Score:', accuracy_score(y_test, y_pred))
print('Classification Report:', classification_report(y_test, y_pred))
print('Confusion Matrix:', confusion_matrix(y_test, y_pred))


# 4 - Training & Evaluating a second classifier

from sklearn.linear_model import LogisticRegression

lmodel = LogisticRegression(max_iter=2000, random_state=42)

lmodel.fit(X_train,y_train)


y_pred_log = lmodel.predict(X_test)


# accuracy statistics

print('Accuracy Score:', accuracy_score(y_test, y_pred_log))
print('Classification Report:', classification_report(y_test, y_pred_log))
print('Confusion Matrix:', confusion_matrix(y_test, y_pred_log))


# 5 - Prediction on actual data (test.csv)

df_real= pd.read_csv('test.csv')


df_real.isnull().sum()


# Fill missing Age values with the median
df_real['Age'].fillna(df_real['Age'].median(), inplace=True)

# Fill missing Embarked values with the mode (most common port)
df_real['Fare'].fillna(df_real['Fare'].mode()[0], inplace=True)

# Drop Cabin — too many missing values
df_real.drop('Cabin', axis=1, inplace=True)

# Drop irrelevant columns that won’t help model prediction
df_real.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)


df_real.isnull().sum()


df_real= pd.get_dummies(df_real, columns=['Embarked', 'Sex'], drop_first=True)


# predicting directly on df_real 

y_fpred = fmodel.predict(df_real)


submission = pd.DataFrame({
    'PassengerId': pd.read_csv("test.csv")['PassengerId'],
    'Survived': y_fpred
})
submission.to_csv("submission.csv", index=False)
